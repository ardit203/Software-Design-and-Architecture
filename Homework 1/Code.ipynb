{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 222\u001b[0m\n\u001b[0;32m    218\u001b[0m     save_stock_data_to_excel(existing_stock_data)\n\u001b[0;32m    219\u001b[0m     save_issuers_to_excel(issuers)\n\u001b[1;32m--> 222\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 181\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Load existing stock data (if any)\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     existing_stock_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstock_data.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     existing_stock_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()  \u001b[38;5;66;03m# If no existing data, create an empty DataFrame\u001b[39;00m\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    777\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 778\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    613\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    614\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 615\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# trim trailing empty elements\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[0;32m     78\u001b[0m     parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src,\n\u001b[0;32m     79\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     80\u001b[0m                              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only,\n\u001b[0;32m     81\u001b[0m                              epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     82\u001b[0m                              date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats,\n\u001b[0;32m     83\u001b[0m                              timedelta_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_timedelta_formats)\n\u001b[1;32m---> 85\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Faculty\\5th Semester\\Software Design and Architecture\\HomeWorks\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    138\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[0;32m    139\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    154\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\xml\\etree\\ElementTree.py:1238\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1012\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m-> 1012\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m   1014\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1102\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1102\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\zipfile\\__init__.py:1027\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[1;34m(self, newdata)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "#Filter 1\n",
    "def fetch_issuers():\n",
    "    url = 'https://www.mse.mk/en/stats/symbolhistory/KMB'  \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to retrieve data\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the dropdown menu for issuers\n",
    "    issuers_dropdown = soup.find('select', {'id': 'Code'})  \n",
    "    issuers = []\n",
    "\n",
    "    for option in issuers_dropdown.find_all('option'):\n",
    "        code = option.get('value')\n",
    "        name = option.text\n",
    "        if code and not any(char.isdigit() for char in code):  \n",
    "            issuers.append({'Issuer Code': code})\n",
    "\n",
    "    # Convert to DataFrame and return\n",
    "    return pd.DataFrame(issuers)\n",
    "\n",
    "\n",
    "#Filter 2\n",
    "def check_last_date_of_data(issuer_code, df):\n",
    "        if(df.empty):\n",
    "            return None\n",
    "        # Filter the data for the given issuer\n",
    "        issuer_data = df[df['Issuer Code'] == issuer_code]\n",
    "        #print(issuer_data)\n",
    "        \n",
    "        if not issuer_data.empty:\n",
    "            # Ensure the 'Date' column is in datetime format\n",
    "            issuer_data['Date'] = pd.to_datetime(issuer_data['Date'], errors='coerce')\n",
    "            \n",
    "            # Get the last available date\n",
    "            last_date = issuer_data['Date'].max()\n",
    "            \n",
    "            if pd.isna(last_date):\n",
    "                print(f\"Invalid date entries found for {issuer_code}.\")\n",
    "            else:\n",
    "                # Return the date in 'm/d/y' format\n",
    "                last_date_str = last_date.strftime(\"%m/%d/%Y\")\n",
    "                #print(f\"Last data for {issuer_code} is from {last_date_str}\")\n",
    "                return last_date_str\n",
    "        else:\n",
    "            print(f\"No data found for {issuer_code}, need to fetch from the last 10 years.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "#Filter 3\n",
    "def parse_cells(row, code):\n",
    "        translation_table = str.maketrans({',': '.',\n",
    "                                           '.': ','})\n",
    "\n",
    "        cells = row.find_all('td')\n",
    "        date = cells[0].text\n",
    "        last_trade_price = cells[1].text.translate(translation_table)\n",
    "        max = cells[2].text.translate(translation_table)\n",
    "        min = cells[3].text.translate(translation_table)\n",
    "        avg_price = cells[4].text.translate(translation_table)\n",
    "        chg = cells[5].text.translate(translation_table)\n",
    "        volume = cells[6].text.translate(translation_table)\n",
    "        turnover_in_best = cells[7].text.translate(translation_table)\n",
    "        total_turnover = cells[8].text.translate(translation_table)\n",
    "\n",
    "        return [code, date, last_trade_price, max, min, avg_price, chg, volume, turnover_in_best, total_turnover]\n",
    "\n",
    "\n",
    "def fetch_stock_data(issuer_code, start_date, end_date):\n",
    "    base_url = \"https://www.mse.mk/en/stats/symbolhistory\"\n",
    "    url = f\"{base_url}/{issuer_code}\"\n",
    "\n",
    "    from_date_str = start_date.strftime(\"%m.%d.%y\")\n",
    "    to_date_str = end_date.strftime(\"%m.%d.%y\")\n",
    "    form_data = {\n",
    "        'FromDate': from_date_str,\n",
    "        'ToDate': to_date_str,\n",
    "    }\n",
    "    print(f\"Scraping data from {from_date_str} to {to_date_str} for {issuer_code}\")\n",
    "    response = requests.post(url, data=form_data)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Successfully fetched data\")\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'id': 'resultsTable'})\n",
    "\n",
    "        if table is None:\n",
    "            print(\"Table not found.\")\n",
    "            return None\n",
    "\n",
    "        rows = table.find_all('tr')\n",
    "        data = []\n",
    "        for row in rows[1:]:\n",
    "            parsed_row = parse_cells(row, issuer_code)\n",
    "            if parsed_row:\n",
    "                data.append(parsed_row)\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Failed to fetch data\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "#Filter 4\n",
    "def scrape_last_10_years(issuer_code):\n",
    "    # Set the end date to today's date\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    # List to store all data\n",
    "    all_data = []\n",
    "\n",
    "    # Start from today and move backward one year at a time\n",
    "    current_end_date = today\n",
    "\n",
    "    # Loop to cover each year until 10 years ago\n",
    "    for _ in range(10):\n",
    "        # Calculate the start date, one year ago from the current end date\n",
    "        current_start_date = current_end_date.replace(year=current_end_date.year - 1)\n",
    "\n",
    "        # If the calculated start date goes beyond the 10-year limit, adjust it\n",
    "        ten_years_ago = today.replace(year=today.year - 10)\n",
    "        if current_start_date < ten_years_ago:\n",
    "            current_start_date = ten_years_ago\n",
    "\n",
    "        \n",
    "        \n",
    "        # Fetch data for the current year range\n",
    "        year_data = fetch_stock_data(issuer_code, current_start_date, current_end_date)\n",
    "        if year_data:\n",
    "            all_data.extend(year_data)\n",
    "        # Move the end date backward for the next iteration\n",
    "        current_end_date = current_start_date - datetime.timedelta(days=1)\n",
    "\n",
    "    # Convert the data into a DataFrame\n",
    "    df = pd.DataFrame(all_data, columns=[\"Issuer Code\",\"Date\", \"Last trade price\", \"Max\", \"Min\", \"Avg.Price\", \"%chg.\", \"Volume\", \"Turnover in BEST in denars\", \"Total turnover in denars\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "#Filter 5\n",
    "def save_issuers_to_excel(df, filename='issuers.xlsx'):\n",
    "    try:\n",
    "        # Try to load the existing Excel file for issuers\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name='Issuers', index=False)\n",
    "            print(f\"Issuers data saved to '{filename}' with 'Issuers' sheet.\")\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new file with the 'Issuers' sheet\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, sheet_name='Issuers', index=False)\n",
    "            print(f\"Excel file '{filename}' created with 'Issuers' sheet.\")\n",
    "\n",
    "\n",
    "def save_stock_data_to_excel(df, filename='stock_data.xlsx'):\n",
    "    try:\n",
    "        # Try to load the existing Excel file for stock data\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name='Stock Data', index=False)\n",
    "            print(f\"Stock data saved to '{filename}' with 'Stock Data' sheet.\")\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new file with the 'Stock Data' sheet\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, sheet_name='Stock Data', index=False)\n",
    "            print(f\"Excel file '{filename}' created with 'Stock Data' sheet.\")\n",
    "\n",
    "#Main Pipeline\n",
    "def main():\n",
    "    issuers = fetch_issuers()\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Load existing stock data (if any)\n",
    "    try:\n",
    "        existing_stock_data = pd.read_excel('stock_data.xlsx')\n",
    "    except FileNotFoundError:\n",
    "        existing_stock_data = pd.DataFrame()  # If no existing data, create an empty DataFrame\n",
    "\n",
    "    for code in issuers['Issuer Code'].values:\n",
    "        # Check the last available date for the issuer\n",
    "        last_date = check_last_date_of_data(code,existing_stock_data)\n",
    "        \n",
    "        if last_date:\n",
    "            # If there is data, fetch the new data starting from the next day after the last date\n",
    "            last_date_obj = datetime.datetime.strptime(last_date, \"%m/%d/%Y\").date()\n",
    "            next_start_date = last_date_obj + datetime.timedelta(days=1)\n",
    "            \n",
    "            # Fetch the new stock data starting from the next day after the last available date\n",
    "            new_data = fetch_stock_data(code, next_start_date, datetime.date.today())\n",
    "            if new_data:\n",
    "                new_df = pd.DataFrame(new_data, columns=[\"Issuer Code\", \"Date\", \"Last trade price\", \"Max\", \"Min\", \"Avg.Price\", \"%chg.\", \"Volume\", \"Turnover in BEST in denars\", \"Total turnover in denars\"])\n",
    "                \n",
    "                # Separate the existing data for the issuer from the entire DataFrame\n",
    "                existing_issuer_data = existing_stock_data[existing_stock_data['Issuer Code'] == code]\n",
    "                \n",
    "                # Prepend new data on top of the existing data for this issuer\n",
    "                updated_issuer_data = pd.concat([new_df, existing_issuer_data], ignore_index=True)\n",
    "                \n",
    "                # Replace the old data for this issuer code with the updated data\n",
    "                existing_stock_data = existing_stock_data[existing_stock_data['Issuer Code'] != code]\n",
    "                \n",
    "                # Add the updated data for the issuer back into the entire DataFrame\n",
    "                existing_stock_data = pd.concat([existing_stock_data, updated_issuer_data], ignore_index=True)\n",
    "        else:\n",
    "            # If no data is found for the issuer, fetch the last 10 years of data\n",
    "            new_df = scrape_last_10_years(code)\n",
    "            \n",
    "            # Add the new data to the DataFrame\n",
    "            existing_stock_data = pd.concat([existing_stock_data, new_df], ignore_index=True)\n",
    "\n",
    "    # Save the updated stock data to the Excel file\n",
    "    save_stock_data_to_excel(existing_stock_data)\n",
    "    save_issuers_to_excel(issuers)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
